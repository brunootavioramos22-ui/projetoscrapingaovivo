# ğŸ“š Web Scraping - Books to Scrape

Projeto de Web Scraping desenvolvido com **Python** e **Scrapy** para extraÃ§Ã£o automatizada de dados do site de testes:

ğŸ”— https://books.toscrape.com/catalogue/page-1.html

---

## ğŸš€ Objetivo

Coletar automaticamente informaÃ§Ãµes detalhadas de todos os livros disponÃ­veis no site, incluindo:

- ğŸ“Œ TÃ­tulo
- ğŸ’° PreÃ§o
- ğŸ“ DescriÃ§Ã£o
- ğŸ“‚ Categoria
- ğŸ“¦ Disponibilidade (Estoque)
- ğŸ–¼ URL da imagem
- â¬‡ Download automÃ¡tico das imagens

---

## ğŸ›  Tecnologias Utilizadas

- Python 3.14
- Scrapy 2.13.4
- Conda (Ambiente Virtual)
- PowerShell / Anaconda Prompt

---

## ğŸ“‚ Estrutura do Projeto
primeiraspider/
â”‚
â”œâ”€â”€ primeiraspider/
â”‚
â””â”€â”€ scrapy.cfg
â”œâ”€â”€ spiders/
â”‚ â””â”€â”€ books.py
â”œâ”€â”€ settings.py
â”œâ”€â”€ items.py

---

## âš™ï¸ Como Funciona

### 1ï¸âƒ£ NavegaÃ§Ã£o

A spider:

- Acessa a pÃ¡gina inicial do catÃ¡logo
- Percorre automaticamente todas as pÃ¡ginas (paginaÃ§Ã£o)
- Coleta os links individuais de cada livro

### 2ï¸âƒ£ ExtraÃ§Ã£o

Para cada livro, o sistema acessa sua pÃ¡gina individual e extrai:

```python
{
    'titulo': ...,
    'preco': ...,
    'descricao': ...,
    'categoria': ...,
    'estoque': ...,
    'image_urls': [...]
}
``` 

 ### ğŸ—ºï¸ Download AutomÃ¡tico de Imagens

O projeto utiliza o ImagesPipeline do Scrapy para baixar automaticamente as imagens dos livros.

ConfiguraÃ§Ã£o no settings.py:

ITEM_PIPELINES = {
    'scrapy.pipelines.images.ImagesPipeline': 1,
}

IMAGES_STORE = 'imagens'

As imagens sÃ£o armazenadas na pasta:

imagens/full/

### â–¶ï¸ Como Executar:

  1ï¸âƒ£ Clone o repositÃ³rio:

git clone https://github.com/seu-usuario/seu-repositorio.git

2ï¸âƒ£ Acesse a pasta do projeto:

``` bash
 cd primeiraspider
```
3ï¸âƒ£ Ative o ambiente virtual (se estiver usando Conda):

``` bash
 conda activate primeiraspider
```
4ï¸âƒ£ Execute a spider:

```bash
 scrapy crawl books -O livros.json
```
### ğŸ“Š Resultado

O arquivo livros.json serÃ¡ gerado contendo todos os livros extraÃ­dos do site em formato estruturado.

Exemplo:
  ``` json
{
  "titulo": "A Light in the Attic",
  "preco": "Â£51.77",
  "descricao": "...",
  "categoria": "Poetry",
  "estoque": "In stock (22 available)"
}
  ```
### ğŸ§  Aprendizados

Durante o desenvolvimento foram aplicados conceitos como:

Web Scraping estruturado

Seletores CSS e XPath

Tratamento de dados com normalize-space()

ConversÃ£o de URLs relativas para absolutas

AutomaÃ§Ã£o de paginaÃ§Ã£o

Download automÃ¡tico de mÃ­dia
